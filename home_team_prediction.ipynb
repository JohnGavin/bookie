{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "import bookie_package as bp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons_home = pd.read_pickle('df_both_seasons_essentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add avg Home Team Goal Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_both_seasons = bp.averages.avg_goal_diff(df_both_seasons_home, 'AVGHTGDIFF', 'HomeTeam', 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons = bp.averages.from_dict_value_to_df(d_both_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons=df_both_seasons.sort_values(['Year', 'Month','Day'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_both_seasons.to_pickle('df_both_seasons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fthg_per_team=bp.averages.avg_goals(df_both_seasons, 'AVGFTHG', 'HomeTeam', 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_both_seasons = bp.averages.from_dict_value_to_df(avg_fthg_per_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons=df_both_seasons.sort_values(['Year', 'Month','Day'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>...</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HTGDIFF</th>\n",
       "      <th>ATGDIFF</th>\n",
       "      <th>AVGHTGDIFF</th>\n",
       "      <th>AVGFTHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>Paderborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>Schalke 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.791667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Month  Year       HomeTeam       AwayTeam  FTHG  FTAG  HS  AS  HST  \\\n",
       "139   18     12  2019     Leverkusen         Hertha   NaN   NaN NaN NaN  NaN   \n",
       "140   18     12  2019     M'gladbach      Paderborn   NaN   NaN NaN NaN  NaN   \n",
       "141   18     12  2019      Wolfsburg     Schalke 04   NaN   NaN NaN NaN  NaN   \n",
       "142   18     12  2019  Ein Frankfurt        FC Koln   NaN   NaN NaN NaN  NaN   \n",
       "143   18     12  2019       Freiburg  Bayern Munich   NaN   NaN NaN NaN  NaN   \n",
       "\n",
       "     ...  HF  AF  HY  AY  HR  AR  HTGDIFF  ATGDIFF  AVGHTGDIFF   AVGFTHG  \n",
       "139  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.400000  1.760000  \n",
       "140  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.760000  2.080000  \n",
       "141  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.520000  1.800000  \n",
       "142  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.720000  1.960000  \n",
       "143  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.416667  1.791667  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both_seasons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Columns with previous HTGDIFF for each HomeTeam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_HTGDIFF=bp.averages.previous_data(df_both_seasons, 'HomeTeam', 'HTGDIFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_HTGDIFF = bp.averages.from_dict_value_to_df(team_with_past_HTGDIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_HTGDIFF = df_team_with_past_HTGDIFF.reindex(columns=[\n",
    "    'Day', 'Month', 'Year', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "    'HTGDIFF', 'ATGDIFF', 'AVGHTGDIFF','AVGFTHG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'HTGDIFF_1', 'HTGDIFF_2', 'HTGDIFF_3', 'HTGDIFF_4', 'HTGDIFF_5', 'HTGDIFF_6', 'HTGDIFF_7',\n",
    "    'HTGDIFF_8', 'HTGDIFF_9', 'HTGDIFF_10', 'HTGDIFF_11', 'HTGDIFF_12', 'HTGDIFF_13', 'HTGDIFF_14', 'HTGDIFF_15', 'HTGDIFF_16', 'HTGDIFF_17', 'HTGDIFF_18', 'HTGDIFF_19',\n",
    "    'HTGDIFF_20', 'HTGDIFF_21', 'HTGDIFF_22', 'HTGDIFF_23'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_HTGDIFF.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_HST=bp.averages.previous_data(df_team_with_past_HTGDIFF, 'HomeTeam', 'HST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_HST = bp.averages.from_dict_value_to_df(team_with_past_HST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "df_team_with_past_HST = df_team_with_past_HST.reindex(columns=[ 'Day',\n",
    "    'Month',\n",
    "    'Year',\n",
    "    'HomeTeam',\n",
    "    'AwayTeam',\n",
    "    'FTHG',\n",
    "    'FTAG',\n",
    "    'HTGDIFF',\n",
    "    'ATGDIFF',\n",
    "    'AVGHTGDIFF',\n",
    "    'AVGFTHG',\n",
    "    'HS',\n",
    "    'AS',\n",
    "    'HST',\n",
    "    'AST',\n",
    "    'HC',\n",
    "    'AC',\n",
    "    'HF',\n",
    "    'AF',\n",
    "    'HY',\n",
    "    'AY',\n",
    "    'HR',\n",
    "    'AR',\n",
    "    'HTGDIFF_1',\n",
    "    'HTGDIFF_2',\n",
    "    'HTGDIFF_3',\n",
    "    'HTGDIFF_4',\n",
    "    'HTGDIFF_5',\n",
    "    'HTGDIFF_6',\n",
    "    'HTGDIFF_7',\n",
    "    'HTGDIFF_8',\n",
    "    'HTGDIFF_9',\n",
    "    'HTGDIFF_10',\n",
    "    'HTGDIFF_11',\n",
    "    'HTGDIFF_12',\n",
    "    'HTGDIFF_13',\n",
    "    'HTGDIFF_14',\n",
    "    'HTGDIFF_15',\n",
    "    'HTGDIFF_16',\n",
    "    'HTGDIFF_17',\n",
    "    'HTGDIFF_18',\n",
    "    'HTGDIFF_19',\n",
    "    'HTGDIFF_20',\n",
    "    'HTGDIFF_21',\n",
    "    'HTGDIFF_22',\n",
    "    'HTGDIFF_23',\n",
    "    'HST_1',\n",
    "    'HST_2',\n",
    "    'HST_3',\n",
    "    'HST_4',\n",
    "    'HST_5',\n",
    "    'HST_6',\n",
    "    'HST_7',\n",
    "    'HST_8',\n",
    "    'HST_9',\n",
    "    'HST_10',\n",
    "    'HST_11',\n",
    "    'HST_12',\n",
    "    'HST_13',\n",
    "    'HST_14',\n",
    "    'HST_15',\n",
    "    'HST_16',\n",
    "    'HST_17',\n",
    "    'HST_18',\n",
    "    'HST_19',\n",
    "    'HST_20',\n",
    "    'HST_21',\n",
    "    'HST_22',\n",
    "    'HST_23' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_FTHG = bp.averages.previous_data(df_team_with_past_HST, 'HomeTeam', 'FTHG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTHG = bp.averages.from_dict_value_to_df(team_with_past_FTHG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "  df_team_with_past_FTHG = df_team_with_past_FTHG.reindex(columns=[ 'Day',\n",
    "    'Month',\n",
    "    'Year',\n",
    "    'HomeTeam',\n",
    "    'AwayTeam',\n",
    "    'FTHG',\n",
    "    'FTAG',\n",
    "    'HTGDIFF',\n",
    "    'ATGDIFF',\n",
    "    'AVGHTGDIFF',\n",
    "    'AVGFTHG',\n",
    "    'HS',\n",
    "    'AS',\n",
    "    'HST',\n",
    "    'AST',\n",
    "    'HC',\n",
    "    'AC',\n",
    "    'HF',\n",
    "    'AF',\n",
    "    'HY',\n",
    "    'AY',\n",
    "    'HR',\n",
    "    'AR',\n",
    "    'HTGDIFF_1',\n",
    "    'HTGDIFF_2',\n",
    "    'HTGDIFF_3',\n",
    "    'HTGDIFF_4',\n",
    "    'HTGDIFF_5',\n",
    "    'HTGDIFF_6',\n",
    "    'HTGDIFF_7',\n",
    "    'HTGDIFF_8',\n",
    "    'HTGDIFF_9',\n",
    "    'HTGDIFF_10',\n",
    "    'HTGDIFF_11',\n",
    "    'HTGDIFF_12',\n",
    "    'HTGDIFF_13',\n",
    "    'HTGDIFF_14',\n",
    "    'HTGDIFF_15',\n",
    "    'HTGDIFF_16',\n",
    "    'HTGDIFF_17',\n",
    "    'HTGDIFF_18',\n",
    "    'HTGDIFF_19',\n",
    "    'HTGDIFF_20',\n",
    "    'HTGDIFF_21',\n",
    "    'HTGDIFF_22',\n",
    "    'HTGDIFF_23',\n",
    "    'HST_1',\n",
    "    'HST_2',\n",
    "    'HST_3',\n",
    "    'HST_4',\n",
    "    'HST_5',\n",
    "    'HST_6',\n",
    "    'HST_7',\n",
    "    'HST_8',\n",
    "    'HST_9',\n",
    "    'HST_10',\n",
    "    'HST_11',\n",
    "    'HST_12',\n",
    "    'HST_13',\n",
    "    'HST_14',\n",
    "    'HST_15',\n",
    "    'HST_16',\n",
    "    'HST_17',\n",
    "    'HST_18',\n",
    "    'HST_19',\n",
    "    'HST_20',\n",
    "    'HST_21',\n",
    "    'HST_22',\n",
    "    'HST_23',\n",
    "    'FTHG_1',\n",
    "    'FTHG_2',\n",
    "    'FTHG_3',\n",
    "    'FTHG_4',\n",
    "    'FTHG_5',\n",
    "    'FTHG_6',\n",
    "    'FTHG_7',\n",
    "    'FTHG_8',\n",
    "    'FTHG_9',\n",
    "    'FTHG_10',\n",
    "    'FTHG_11',\n",
    "    'FTHG_12',\n",
    "    'FTHG_13',\n",
    "    'FTHG_14',\n",
    "    'FTHG_15',\n",
    "    'FTHG_16',\n",
    "    'FTHG_17',\n",
    "    'FTHG_18',\n",
    "    'FTHG_19',\n",
    "    'FTHG_20',\n",
    "    'FTHG_21',\n",
    "    'FTHG_22',\n",
    "    'FTHG_23' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTHG.sort_values(['Year', 'Month','Day'], ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTHG.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_team_with_past_FTHG = df_team_with_past_FTHG[['Day', 'Month', 'Year', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "    'HTGDIFF', 'ATGDIFF', 'AVGHTGDIFF', 'AVGFTHG','HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'HTGDIFF_1', 'HTGDIFF_2', 'HTGDIFF_3', 'HTGDIFF_4', 'HTGDIFF_5', 'HTGDIFF_6', 'HTGDIFF_7',\n",
    "    'HTGDIFF_8', 'HTGDIFF_9', 'HTGDIFF_10',  'HST_1',\n",
    " 'HST_2',\n",
    " 'HST_3',\n",
    " 'HST_4',\n",
    " 'HST_5',\n",
    " 'HST_6',\n",
    " 'HST_7',\n",
    " 'HST_8',\n",
    " 'HST_9',\n",
    " 'HST_10',\n",
    " 'FTHG_1',\n",
    " 'FTHG_2',\n",
    " 'FTHG_3',\n",
    " 'FTHG_4',\n",
    " 'FTHG_5',\n",
    " 'FTHG_6',\n",
    " 'FTHG_7',\n",
    " 'FTHG_8',\n",
    " 'FTHG_9',\n",
    " 'FTHG_10'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTHG.to_excel('df_team_with_past_FTHG_home.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Month', 'Year', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
       "       'HTGDIFF', 'ATGDIFF', 'AVGHTGDIFF', 'AVGFTHG', 'HS', 'AS', 'HST', 'AST',\n",
       "       'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'HTGDIFF_1',\n",
       "       'HTGDIFF_2', 'HTGDIFF_3', 'HTGDIFF_4', 'HTGDIFF_5', 'HTGDIFF_6',\n",
       "       'HTGDIFF_7', 'HTGDIFF_8', 'HTGDIFF_9', 'HTGDIFF_10', 'HST_1', 'HST_2',\n",
       "       'HST_3', 'HST_4', 'HST_5', 'HST_6', 'HST_7', 'HST_8', 'HST_9', 'HST_10',\n",
       "       'FTHG_1', 'FTHG_2', 'FTHG_3', 'FTHG_4', 'FTHG_5', 'FTHG_6', 'FTHG_7',\n",
       "       'FTHG_8', 'FTHG_9', 'FTHG_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team_with_past_FTHG.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_team_with_past_FTHG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.drop(['HomeTeam', 'AwayTeam'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (450, 51)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of features:', df_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels and Convert Data to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(df_result['FTHG'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "df_result= df_result.drop(['Year','Day','Month','HTGDIFF_10','FTHG_6','FTHG_8', 'FTHG_9', 'FTHG_10','FTHG', 'FTAG', 'HTGDIFF', 'ATGDIFF', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR'], axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_result.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "df_result = np.array(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    df_result, labels, test_size = 0.25,random_state = 42\n",
    ")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (337, 27)\n",
      "Training Labels Shape: (337,)\n",
      "Testing Features Shape: (113, 27)\n",
      "Testing Labels Shape: (113,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  1.1 Goals.\n"
     ]
    }
   ],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = train_features[:, feature_list.index('AVGFTHG')]\n",
    "# AVerage goals made by home team\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - train_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'Goals.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = bp.prediction.random_forrest(train_features, train_labels, n_estimators=1000,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.22 Goals.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Goals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#for i in zip(np.round(predictions,0), test_labels):\n",
    " #   print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.96 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "err = errors/test_labels\n",
    "err[np.isnan(err)] = 0\n",
    "mape = err * 100\n",
    "mape[mape == inf] = 0\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree_home.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree_home.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree_home.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth of this tree is: 16\n"
     ]
    }
   ],
   "source": [
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit depth of tree to 2 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 4, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree_home.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree_home.dot')\n",
    "\n",
    "graph.write_png('small_tree_home.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: AVGFTHG              Importance: 0.16517\n",
      "Variable: AVGHTGDIFF           Importance: 0.10169\n",
      "Variable: HST_1                Importance: 0.04986\n",
      "Variable: HTGDIFF_7            Importance: 0.04686\n",
      "Variable: HTGDIFF_8            Importance: 0.04234\n",
      "Variable: HST_5                Importance: 0.03912\n",
      "Variable: HTGDIFF_3            Importance: 0.03631\n",
      "Variable: HST_2                Importance: 0.03557\n",
      "Variable: HST_3                Importance: 0.03497\n",
      "Variable: HST_10               Importance: 0.03411\n",
      "Variable: HST_7                Importance: 0.03372\n",
      "Variable: HST_4                Importance: 0.03351\n",
      "Variable: HTGDIFF_1            Importance: 0.03308\n",
      "Variable: HTGDIFF_2            Importance: 0.03287\n",
      "Variable: HST_8                Importance: 0.02584\n",
      "Variable: HTGDIFF_9            Importance: 0.0257\n",
      "Variable: HTGDIFF_6            Importance: 0.02455\n",
      "Variable: HST_6                Importance: 0.02376\n",
      "Variable: HTGDIFF_4            Importance: 0.02351\n",
      "Variable: FTHG_1               Importance: 0.02347\n",
      "Variable: FTHG_4               Importance: 0.02307\n",
      "Variable: HTGDIFF_5            Importance: 0.02113\n",
      "Variable: HST_9                Importance: 0.02069\n",
      "Variable: FTHG_2               Importance: 0.02005\n",
      "Variable: FTHG_7               Importance: 0.01965\n",
      "Variable: FTHG_3               Importance: 0.01609\n",
      "Variable: FTHG_5               Importance: 0.0133\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Optimization through Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                                           11, 12, 12, 12, 12, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([  10,   30,   50,   70,   90,  111,  131,  151,  171,  191,  212,\n",
       "        232,  252,  272,  292,  313,  333,  353,  373,  393,  414,  434,\n",
       "        454,  474,  494,  515,  535,  555,  575,  595,  616,  636,  656,\n",
       "        676,  696,  717,  737,  757,  777,  797,  818,  838,  858,  878,\n",
       "        898,  919,  939,  959,  979, 1000])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "   'n_estimators': np.linspace(10, 1000).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=42)\n",
    "\n",
    "# Fit \n",
    "rs.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = bp.prediction.random_forrest(\n",
    "    train_features, train_labels, \n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    random_state = 42,\n",
    "    min_samples_split = best_params['min_samples_split'],\n",
    "    max_leaf_nodes = best_params['max_leaf_nodes'],\n",
    "    max_features = best_params['max_features'],\n",
    "    max_depth = best_params['max_depth'],\n",
    "    bootstrap = best_params['bootstrap']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.21 Goals.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Goals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.06 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "err = errors/test_labels\n",
    "err[np.isnan(err)] = 0\n",
    "mape = err * 100\n",
    "mape[mape == inf] = 0\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_games=df_result[:9]\n",
    "predictions_next_games = rf.predict(next_games)\n",
    "next_games_predictions=np.round(predictions_next_games,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>...</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HTGDIFF</th>\n",
       "      <th>ATGDIFF</th>\n",
       "      <th>AVGHTGDIFF</th>\n",
       "      <th>AVGFTHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>Paderborn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>Schalke 04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>3.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>Fortuna Dusseldorf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Union Berlin</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Month  Year       HomeTeam            AwayTeam  FTHG  FTAG  HS  AS  \\\n",
       "139   18     12  2019     Leverkusen              Hertha   2.0   NaN NaN NaN   \n",
       "140   18     12  2019     M'gladbach           Paderborn   2.0   NaN NaN NaN   \n",
       "141   18     12  2019      Wolfsburg          Schalke 04   1.0   NaN NaN NaN   \n",
       "142   18     12  2019  Ein Frankfurt             FC Koln   1.0   NaN NaN NaN   \n",
       "143   18     12  2019       Freiburg       Bayern Munich   1.0   NaN NaN NaN   \n",
       "135   17     12  2019  Werder Bremen               Mainz   2.0   NaN NaN NaN   \n",
       "136   17     12  2019       Dortmund          RB Leipzig   2.0   NaN NaN NaN   \n",
       "137   17     12  2019       Augsburg  Fortuna Dusseldorf   1.0   NaN NaN NaN   \n",
       "138   17     12  2019   Union Berlin          Hoffenheim   1.0   NaN NaN NaN   \n",
       "\n",
       "     HST  ...  HF  AF  HY  AY  HR  AR  HTGDIFF  ATGDIFF  AVGHTGDIFF   AVGFTHG  \n",
       "139  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.400000  1.760000  \n",
       "140  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.760000  2.080000  \n",
       "141  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.520000  1.800000  \n",
       "142  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.720000  1.960000  \n",
       "143  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.416667  1.791667  \n",
       "135  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.125000  1.791667  \n",
       "136  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    1.833333  3.125000  \n",
       "137  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.125000  1.958333  \n",
       "138  NaN  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    0.375000  1.500000  \n",
       "\n",
       "[9 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both_seasons.head(9)['FTHG'] = next_games_predictions\n",
    "df_both_seasons.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
